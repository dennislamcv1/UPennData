{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7b4f14e82b05dd891724e27900f063c6",
     "grade": false,
     "grade_id": "cell-3f6367686e0e0548",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Practice Assignment 1\n",
    "# Loading, Inspecting, & Querying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c07a0c20a0ca6096cbd5eac143144e83",
     "grade": false,
     "grade_id": "cell-2b7743af336e7e56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For each question, there are instructions in each cell. Follow those instructions and write the code after each block of:\n",
    "\n",
    "YOUR CODE HERE\n",
    "\n",
    "Please use the exact variable name if it is specified in the comment.\n",
    "\n",
    "We’ll run a Python test script against your program to test whether each function implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a17245b142cd4416bee33ae96b0ad9a6",
     "grade": true,
     "grade_id": "init_test",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "###########################################################\n",
    "### EXECUTE THIS CELL BEFORE YOU TO TEST YOUR SOLUTIONS ###\n",
    "###########################################################\n",
    "\"\"\"\n",
    "Import all libraries needed for the entire exercise: pandas, numpy, pyplot, and seaborn\n",
    "\"\"\"\n",
    "import imp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nose.tools import assert_equal\n",
    "from pandas.util.testing import assert_frame_equal, assert_series_equal\n",
    "sol = imp.load_compiled(\"sol\", \"./.sol.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9373ecafe8c79e8ad79fcd6ad09d6ddf",
     "grade": false,
     "grade_id": "q1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 01: Loading Data\n",
    "\n",
    "1. First we need to load the dataset into Pandas as dataframes.  We will be working with 3 different csv files:\n",
    "\"geoplaces2.csv\", \"chefmozaccepts.csv\", and \"chefmozcuisine.csv\"\n",
    "\n",
    "2. After loading the data, store the three dataframes in variables named \"restaurant_location_df\",\n",
    "\"restaurant_accept_df\", and \"restaurant_cuisine_df\" respectively\n",
    "\n",
    "3. Get the number of rows for \"restaurant_location_df\" and save it as \"num_rows_restaurant_location\"\n",
    "\n",
    "4. Get the shape of \"restaurant_accept_df\" and save it as a variable named \"shape_restaurant_accept\"\n",
    "\n",
    "5. Get (and display) the first 5 rows for each dataframe and store in variables named \"restaurant_location_df_head\",\n",
    "\"restaurant_accept_df_head\", and \"restaurant_cuisine_df_head\" respectively.  Hint: You can use display() to\n",
    "display dataframes as easy-to-read html tables.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "restaurant_location_df = pd.read_csv(\"geoplaces2.csv\")\n",
    "restaurant_accept_df = pd.read_csv(\"chefmozaccepts.csv\")\n",
    "restaurant_cuisine_df = pd.read_csv(\"chefmozcuisine.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows_restaurant_location = len(restaurant_location_df)\n",
    "num_rows_restaurant_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_restaurant_accept = restaurant_accept_df.shape\n",
    "shape_restaurant_accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_location_df_head = restaurant_location_df.head()\n",
    "\n",
    "restaurant_accept_df_head = restaurant_accept_df.head()\n",
    "\n",
    "restaurant_cuisine_df_head = restaurant_cuisine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "261a268614c5cdbc321cc7b71ac55e85",
     "grade": true,
     "grade_id": "q1_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test restaurant_location_df correct\n",
      "test restaurant_accept_df correct\n",
      "test restaurant_cuisine_df correct\n",
      "test num_rows_restaurant_location correct\n",
      "test shape_restaurant_accept correct\n",
      "test restaurant_location_df_head correct\n",
      "test restaurant_accept_df_head correct\n",
      "test restaurant_cuisine_df_head correct\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "assert_frame_equal(restaurant_location_df, sol.restaurant_location_df)\n",
    "print(\"test restaurant_location_df correct\")\n",
    "assert_frame_equal(restaurant_accept_df, sol.restaurant_accept_df)\n",
    "print(\"test restaurant_accept_df correct\")\n",
    "assert_frame_equal(restaurant_cuisine_df, sol.restaurant_cuisine_df)\n",
    "print(\"test restaurant_cuisine_df correct\")\n",
    "\n",
    "assert_equal(num_rows_restaurant_location, sol.num_rows_restaurant_location)\n",
    "print(\"test num_rows_restaurant_location correct\")\n",
    "assert_equal(shape_restaurant_accept, sol.shape_restaurant_accept)\n",
    "print(\"test shape_restaurant_accept correct\")\n",
    "\n",
    "assert_frame_equal(restaurant_location_df_head, sol.restaurant_location_df_head)\n",
    "print(\"test restaurant_location_df_head correct\")\n",
    "assert_frame_equal(restaurant_accept_df_head, sol.restaurant_accept_df_head)\n",
    "print(\"test restaurant_accept_df_head correct\")\n",
    "assert_frame_equal(restaurant_cuisine_df_head, sol.restaurant_cuisine_df_head)\n",
    "print(\"test restaurant_cuisine_df_head correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "68813d96417fe79dea45aeecc00fb473",
     "grade": false,
     "grade_id": "q2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 02: Inspecting Data\n",
    "\n",
    "1. In the \"restaurant_location_df\" we can see that there is a column called \"placeID\" which represents\n",
    "the index of each restaurant.  Get a list of all unique \"placeID\"s and store it in a variable called\n",
    "\"unique_id_list\".  Hint: Try using .unique() which can be run on a series (a single column from a dataframe).\n",
    "\n",
    "2. Next we want to see how many different city & states there are. Select only the columns \"city\" and \"state\"\n",
    "and then drop the duplicates.  Save it in a dataframe called \"unique_city_state_df\".\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bed8783a51b1fb944ca34b52f7d624c4",
     "grade": true,
     "grade_id": "q2_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "np.testing.assert_equal(unique_id_list, sol.unique_id_list)\n",
    "print(\"test unique_id_list correct\")\n",
    "assert_frame_equal(unique_city_state_df, sol.unique_city_state_df)\n",
    "print(\"test unique_city_state_df correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8fb77f57b063dda3cb9be255217c3976",
     "grade": false,
     "grade_id": "q3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 03: Cleaning Data\n",
    "\n",
    "1. Check the type of each column in \"restaurant_location_df\".  Hint: Try using .info().\n",
    "\n",
    "2. We want to extract the following columns of data: \"placeID\", \"address\", \"city\", \"state\", \"country\",\n",
    "\"price\" and \"alcohol\".  With only these columns, make a new dataframe called \"new_restaurant_location_df\".\n",
    "\n",
    "3. We want to convert all the columns in our new dataframe \"new_restaurant_location_df\" (except placeID) to pandas string type.\n",
    "Hint: Try using .astype().\n",
    "\n",
    "4. Check the type of each column of the new dataframe \"new_restaurant_location_df\".  Hint: The types should now be\n",
    "different than the old dataframe \"restaurant_location_df\".\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "196876db153d88d20aa8604e0898fea1",
     "grade": true,
     "grade_id": "q3_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "assert_frame_equal(new_restaurant_location_df, sol.new_restaurant_location_df)\n",
    "print(\"test new_restaurant_location_df correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f967218f817e96be66423f6b6fea5742",
     "grade": false,
     "grade_id": "q4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 04: Cleaning Data\n",
    "\n",
    "1. First examine the dataframe \"new_restaurant_location_df\" using display()\n",
    "\n",
    "2. By looking at \"new_restaurant_location_df\", we can see that there are a lot of values that are \"?\",\n",
    "which means the value is unknown.  Now, we want to CHANGE these \"?\" to NaN and store the resulting dataframe\n",
    "as \"new_restaurant_location_df2\".  Hint: NaN can be written using np.nan.\n",
    "\n",
    "3. In the new dataframe \"new_restaurant_location_df2\" remove all NA and NaN values\n",
    "   Hint: Please ensure reset_index(drop=True) after removing NA values.\n",
    "\n",
    "4. Examine the new dataframe \"new_restaurant_location_df2\" with display()\n",
    "\n",
    "5. By looking at \"new_restaurant_location_df2\" we can see that some values have uppercase characters and some\n",
    "have lowercase characters.  For the sake of consistency, convert all values in the dataframe to lowercase.\n",
    "\n",
    "Hint：\n",
    "Methods to Convert Entire Dataframe Columns to Lowercase:\n",
    "\n",
    "Method 1: Using apply() function\n",
    "# Sample code for Method 1\n",
    "import pandas as pd\n",
    "data = {\"name\":[\"Sukesh\",\"Abhishek\",\"Maya\",\"Rahul\"],\"age\":[23,25,26,32],\n",
    "\"city\":[\"Delhi\",\"Noida\",\"Las Vegas\",\"Mumbai\"]}\n",
    "df = pd.DataFrame(data)\n",
    "df2 = df.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "Method 2: Using the applymap() function\n",
    "# Sample code for Method 2\n",
    "import pandas as pd\n",
    "data = {\"name\":[\"Sukesh\",\"Abhishek\",\"Maya\",\"Rahul\"],\"age\":[23,25,26,32],\n",
    "\"city\":[\"Delhi\",\"Noida\",\"Las Vegas\",\"Mumbai\"]}\n",
    "df = pd.DataFrame(data)\n",
    "df2 = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "997cd0159700d0216a77dac4ce241fba",
     "grade": true,
     "grade_id": "q4_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "try:\n",
    "    if new_restaurant_location_df2['placeID'].dtype == 'object':\n",
    "        assert_frame_equal(new_restaurant_location_df2, sol.new_restaurant_location_df2)\n",
    "    elif new_restaurant_location_df2['placeID'].dtype == 'int64':\n",
    "        test_df_for_int64 = sol.new_restaurant_location_df2.copy()\n",
    "        test_df_for_int64['placeID'] = test_df_for_int64['placeID'].astype('int64')\n",
    "        assert_frame_equal(new_restaurant_location_df2, test_df_for_int64)\n",
    "    else:\n",
    "        raise Exception('placeID type is not correct!')\n",
    "    print(\"test new_restaurant_location_df2 correct\")\n",
    "except AssertionError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "13dcbb7aca40b973cd33f7b39e76bf6b",
     "grade": false,
     "grade_id": "q5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 05: Cleaning Data\n",
    "\n",
    "1. We are now going to apply all of the above preprocessing steps for two new .csv files.\n",
    "\n",
    "2. We will be working with \"rating_final.csv\" and \"userprofile.csv\". These tables represent users' ratings\n",
    "for the restaurants and information about their user profiles.  Read the two .csv files \"rating_final.csv\" and\n",
    "\"userprofile.csv\" into two dataframes called \"rating_final_df\" and \"user_profile_df\" respectively.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bdbaf95457284464b5f7f267f74c3bbd",
     "grade": true,
     "grade_id": "q5_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "assert_frame_equal(rating_final_df, sol.rating_final_df)\n",
    "print(\"test rating_final_df correct\")\n",
    "assert_frame_equal(user_profile_df, sol.user_profile_df)\n",
    "print(\"test user_profile_df correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "18439eb0ca681734c5fbf2abeae70685",
     "grade": false,
     "grade_id": "q6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 06: Cleaning Data\n",
    "\n",
    "1. We want to extract the following columns of data from the \"user_profile_df\" dataframe: \"userID\", \"smoker\",\n",
    "\"drink_level\", \"marital_status\", and \"birth_year\".  With only these columns, make a new dataframe called\n",
    "\"user_profile_df2\".\n",
    "\n",
    "2. As before, in \"user_profile_df2\", change the \"?\" values to NaN (np.nan)\n",
    "\n",
    "3. In the new dataframe \"user_profile_df2\" remove all NA and NaN values. \n",
    "   Hint: Please ensure reset_index(drop=True) after removing NA values.\n",
    "\n",
    "4. From \"user_profile_df2\", get a list of all the unique values in the column named \"drink_level\" \n",
    "and save it into variable called \"drink_level_types\"\n",
    "\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "66192848b2d2a5dd9970ea13a22e490c",
     "grade": true,
     "grade_id": "q6_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "assert_frame_equal(user_profile_df2, sol.user_profile_df2)\n",
    "print(\"test user_profile_df2 correct\")\n",
    "np.testing.assert_equal(drink_level_types, sol.drink_level_types)\n",
    "print(\"test drink_level_types correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
