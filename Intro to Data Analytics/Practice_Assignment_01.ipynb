{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7b4f14e82b05dd891724e27900f063c6",
     "grade": false,
     "grade_id": "cell-3f6367686e0e0548",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Practice Assignment 1\n",
    "# Loading, Inspecting, & Querying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c07a0c20a0ca6096cbd5eac143144e83",
     "grade": false,
     "grade_id": "cell-2b7743af336e7e56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For each question, there are instructions in each cell. Follow those instructions and write the code after each block of:\n",
    "\n",
    "YOUR CODE HERE\n",
    "\n",
    "Please use the exact variable name if it is specified in the comment.\n",
    "\n",
    "Weâ€™ll run a Python test script against your program to test whether each function implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a17245b142cd4416bee33ae96b0ad9a6",
     "grade": true,
     "grade_id": "init_test",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "###########################################################\n",
    "### EXECUTE THIS CELL BEFORE YOU TO TEST YOUR SOLUTIONS ###\n",
    "###########################################################\n",
    "\"\"\"\n",
    "Import all libraries needed for the entire exercise: pandas, numpy, pyplot, and seaborn\n",
    "\"\"\"\n",
    "import imp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nose.tools import assert_equal\n",
    "from pandas.util.testing import assert_frame_equal, assert_series_equal\n",
    "sol = imp.load_compiled(\"sol\", \"./.sol.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9373ecafe8c79e8ad79fcd6ad09d6ddf",
     "grade": false,
     "grade_id": "q1",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 01: Loading Data\n",
    "\n",
    "1. First we need to load the dataset into Pandas as dataframes.  We will be working with 3 different csv files:\n",
    "\"geoplaces2.csv\", \"chefmozaccepts.csv\", and \"chefmozcuisine.csv\"\n",
    "\n",
    "2. After loading the data, store the three dataframes in variables named \"restaurant_location_df\",\n",
    "\"restaurant_accept_df\", and \"restaurant_cuisine_df\" respectively\n",
    "\n",
    "3. Get the number of rows for \"restaurant_location_df\" and save it as \"num_rows_restaurant_location\"\n",
    "\n",
    "4. Get the shape of \"restaurant_accept_df\" and save it as a variable named \"shape_restaurant_accept\"\n",
    "\n",
    "5. Get (and display) the first 5 rows for each dataframe and store in variables named \"restaurant_location_df_head\",\n",
    "\"restaurant_accept_df_head\", and \"restaurant_cuisine_df_head\" respectively.  Hint: You can use display() to\n",
    "display dataframes as easy-to-read html tables.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "restaurant_location_df = pd.read_csv(\"geoplaces2.csv\")\n",
    "restaurant_accept_df = pd.read_csv(\"chefmozaccepts.csv\")\n",
    "restaurant_cuisine_df = pd.read_csv(\"chefmozcuisine.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows_restaurant_location = len(restaurant_location_df)\n",
    "num_rows_restaurant_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_restaurant_accept = restaurant_accept_df.shape\n",
    "shape_restaurant_accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_location_df_head = restaurant_location_df.head()\n",
    "\n",
    "restaurant_accept_df_head = restaurant_accept_df.head()\n",
    "\n",
    "restaurant_cuisine_df_head = restaurant_cuisine_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "261a268614c5cdbc321cc7b71ac55e85",
     "grade": true,
     "grade_id": "q1_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test restaurant_location_df correct\n",
      "test restaurant_accept_df correct\n",
      "test restaurant_cuisine_df correct\n",
      "test num_rows_restaurant_location correct\n",
      "test shape_restaurant_accept correct\n",
      "test restaurant_location_df_head correct\n",
      "test restaurant_accept_df_head correct\n",
      "test restaurant_cuisine_df_head correct\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "assert_frame_equal(restaurant_location_df, sol.restaurant_location_df)\n",
    "print(\"test restaurant_location_df correct\")\n",
    "assert_frame_equal(restaurant_accept_df, sol.restaurant_accept_df)\n",
    "print(\"test restaurant_accept_df correct\")\n",
    "assert_frame_equal(restaurant_cuisine_df, sol.restaurant_cuisine_df)\n",
    "print(\"test restaurant_cuisine_df correct\")\n",
    "\n",
    "assert_equal(num_rows_restaurant_location, sol.num_rows_restaurant_location)\n",
    "print(\"test num_rows_restaurant_location correct\")\n",
    "assert_equal(shape_restaurant_accept, sol.shape_restaurant_accept)\n",
    "print(\"test shape_restaurant_accept correct\")\n",
    "\n",
    "assert_frame_equal(restaurant_location_df_head, sol.restaurant_location_df_head)\n",
    "print(\"test restaurant_location_df_head correct\")\n",
    "assert_frame_equal(restaurant_accept_df_head, sol.restaurant_accept_df_head)\n",
    "print(\"test restaurant_accept_df_head correct\")\n",
    "assert_frame_equal(restaurant_cuisine_df_head, sol.restaurant_cuisine_df_head)\n",
    "print(\"test restaurant_cuisine_df_head correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "68813d96417fe79dea45aeecc00fb473",
     "grade": false,
     "grade_id": "q2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 02: Inspecting Data\n",
    "\n",
    "1. In the \"restaurant_location_df\" we can see that there is a column called \"placeID\" which represents\n",
    "the index of each restaurant.  Get a list of all unique \"placeID\"s and store it in a variable called\n",
    "\"unique_id_list\".  Hint: Try using .unique() which can be run on a series (a single column from a dataframe).\n",
    "\n",
    "2. Next we want to see how many different city & states there are. Select only the columns \"city\" and \"state\"\n",
    "and then drop the duplicates.  Save it in a dataframe called \"unique_city_state_df\".\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bed8783a51b1fb944ca34b52f7d624c4",
     "grade": true,
     "grade_id": "q2_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "np.testing.assert_equal(unique_id_list, sol.unique_id_list)\n",
    "print(\"test unique_id_list correct\")\n",
    "assert_frame_equal(unique_city_state_df, sol.unique_city_state_df)\n",
    "print(\"test unique_city_state_df correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8fb77f57b063dda3cb9be255217c3976",
     "grade": false,
     "grade_id": "q3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 03: Cleaning Data\n",
    "\n",
    "1. Check the type of each column in \"restaurant_location_df\".  Hint: Try using .info().\n",
    "\n",
    "2. We want to extract the following columns of data: \"placeID\", \"address\", \"city\", \"state\", \"country\",\n",
    "\"price\" and \"alcohol\".  With only these columns, make a new dataframe called \"new_restaurant_location_df\".\n",
    "\n",
    "3. We want to convert all the columns in our new dataframe \"new_restaurant_location_df\" (except placeID) to pandas string type.\n",
    "Hint: Try using .astype().\n",
    "\n",
    "4. Check the type of each column of the new dataframe \"new_restaurant_location_df\".  Hint: The types should now be\n",
    "different than the old dataframe \"restaurant_location_df\".\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "196876db153d88d20aa8604e0898fea1",
     "grade": true,
     "grade_id": "q3_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "assert_frame_equal(new_restaurant_location_df, sol.new_restaurant_location_df)\n",
    "print(\"test new_restaurant_location_df correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f967218f817e96be66423f6b6fea5742",
     "grade": false,
     "grade_id": "q4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 04: Cleaning Data\n",
    "\n",
    "1. First examine the dataframe \"new_restaurant_location_df\" using display()\n",
    "\n",
    "2. By looking at \"new_restaurant_location_df\", we can see that there are a lot of values that are \"?\",\n",
    "which means the value is unknown.  Now, we want to CHANGE these \"?\" to NaN and store the resulting dataframe\n",
    "as \"new_restaurant_location_df2\".  Hint: NaN can be written using np.nan.\n",
    "\n",
    "3. In the new dataframe \"new_restaurant_location_df2\" remove all NA and NaN values\n",
    "   Hint: Please ensure reset_index(drop=True) after removing NA values.\n",
    "\n",
    "4. Examine the new dataframe \"new_restaurant_location_df2\" with display()\n",
    "\n",
    "5. By looking at \"new_restaurant_location_df2\" we can see that some values have uppercase characters and some\n",
    "have lowercase characters.  For the sake of consistency, convert all values in the dataframe to lowercase.\n",
    "\n",
    "Hintï¼š\n",
    "Methods to Convert Entire Dataframe Columns to Lowercase:\n",
    "\n",
    "Method 1: Using apply() function\n",
    "# Sample code for Method 1\n",
    "import pandas as pd\n",
    "data = {\"name\":[\"Sukesh\",\"Abhishek\",\"Maya\",\"Rahul\"],\"age\":[23,25,26,32],\n",
    "\"city\":[\"Delhi\",\"Noida\",\"Las Vegas\",\"Mumbai\"]}\n",
    "df = pd.DataFrame(data)\n",
    "df2 = df.apply(lambda x: x.astype(str).str.lower())\n",
    "\n",
    "Method 2: Using the applymap() function\n",
    "# Sample code for Method 2\n",
    "import pandas as pd\n",
    "data = {\"name\":[\"Sukesh\",\"Abhishek\",\"Maya\",\"Rahul\"],\"age\":[23,25,26,32],\n",
    "\"city\":[\"Delhi\",\"Noida\",\"Las Vegas\",\"Mumbai\"]}\n",
    "df = pd.DataFrame(data)\n",
    "df2 = df.applymap(lambda s: s.lower() if type(s) == str else s)\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "997cd0159700d0216a77dac4ce241fba",
     "grade": true,
     "grade_id": "q4_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "try:\n",
    "    if new_restaurant_location_df2['placeID'].dtype == 'object':\n",
    "        assert_frame_equal(new_restaurant_location_df2, sol.new_restaurant_location_df2)\n",
    "    elif new_restaurant_location_df2['placeID'].dtype == 'int64':\n",
    "        test_df_for_int64 = sol.new_restaurant_location_df2.copy()\n",
    "        test_df_for_int64['placeID'] = test_df_for_int64['placeID'].astype('int64')\n",
    "        assert_frame_equal(new_restaurant_location_df2, test_df_for_int64)\n",
    "    else:\n",
    "        raise Exception('placeID type is not correct!')\n",
    "    print(\"test new_restaurant_location_df2 correct\")\n",
    "except AssertionError as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "13dcbb7aca40b973cd33f7b39e76bf6b",
     "grade": false,
     "grade_id": "q5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 05: Cleaning Data\n",
    "\n",
    "1. We are now going to apply all of the above preprocessing steps for two new .csv files.\n",
    "\n",
    "2. We will be working with \"rating_final.csv\" and \"userprofile.csv\". These tables represent users' ratings\n",
    "for the restaurants and information about their user profiles.  Read the two .csv files \"rating_final.csv\" and\n",
    "\"userprofile.csv\" into two dataframes called \"rating_final_df\" and \"user_profile_df\" respectively.\n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bdbaf95457284464b5f7f267f74c3bbd",
     "grade": true,
     "grade_id": "q5_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "assert_frame_equal(rating_final_df, sol.rating_final_df)\n",
    "print(\"test rating_final_df correct\")\n",
    "assert_frame_equal(user_profile_df, sol.user_profile_df)\n",
    "print(\"test user_profile_df correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "18439eb0ca681734c5fbf2abeae70685",
     "grade": false,
     "grade_id": "q6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Part 06: Cleaning Data\n",
    "\n",
    "1. We want to extract the following columns of data from the \"user_profile_df\" dataframe: \"userID\", \"smoker\",\n",
    "\"drink_level\", \"marital_status\", and \"birth_year\".  With only these columns, make a new dataframe called\n",
    "\"user_profile_df2\".\n",
    "\n",
    "2. As before, in \"user_profile_df2\", change the \"?\" values to NaN (np.nan)\n",
    "\n",
    "3. In the new dataframe \"user_profile_df2\" remove all NA and NaN values. \n",
    "   Hint: Please ensure reset_index(drop=True) after removing NA values.\n",
    "\n",
    "4. From \"user_profile_df2\", get a list of all the unique values in the column named \"drink_level\" \n",
    "and save it into variable called \"drink_level_types\"\n",
    "\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "66192848b2d2a5dd9970ea13a22e490c",
     "grade": true,
     "grade_id": "q6_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "### TEST YOUR SOLUTION ###\n",
    "##########################\n",
    "\n",
    "assert_frame_equal(user_profile_df2, sol.user_profile_df2)\n",
    "print(\"test user_profile_df2 correct\")\n",
    "np.testing.assert_equal(drink_level_types, sol.drink_level_types)\n",
    "print(\"test drink_level_types correct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
